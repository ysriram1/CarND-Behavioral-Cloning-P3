# Behaviorial Cloning Project

[![Udacity - Self-Driving Car NanoDegree](https://s3.amazonaws.com/udacity-sdc/github/shield-carnd.svg)](http://www.udacity.com/drive)

*Please note that the template provided has been modified to create this report*

**Behavioral Cloning Project - Udacity CarNd**

The goals of this project are the following:
* Use the simulator to collect data of good driving behavior
* Build, a convolution neural network in Keras that predicts steering angles from images
* Train and validate the model with a training and validation set
* Test that the model successfully drives around track one without leaving the road
* Summarize the results with a written report


[//]: # (Image References)

[image1]: ./writeup_images/center.jpg
[image2]: ./writeup_images/turn_left.jpg
[image3]: ./writeup_images/turn_right.jpg

---
### Files Submitted & Code Quality

#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode

My project includes the following files:
* network.py containing the script to create and train the model
* drive.py for driving the car in autonomous mode
* model_2_gpu.h5 containing the chosen trained convolution neural network
* README.md containing the project report
* run2output_video.mp4 containing a video recording of the car driving autonomously

#### 2. Submission includes functional code
Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing
```sh
python drive.py model_2_gpu.h5
```

#### 3. Submission code is usable and readable

The network.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.

#### 4. System Configuration and Dependencies

**System configuration:**
- Intel i7 4.20GHz
- Nvidia GTX 1070 (Tensorflow GPU was used)
- 32 GB of RAM
- Windows 10

**Dependencies:**
- Tensorflow
- Keras
- numpy
- matplotlib
- pickle
- random
- os

### Model Architecture and Training Strategy

#### 1. An appropriate model architecture has been employed

Here is a summary of the final Convolutional Neural Network architecture used:

*lines 83 to 114 in network.py*

| Layer         		|     Parameters	        					|
|:---------------------:|:---------------------------------------------:|
| Input         		| 160x32x3 RGB image   							|
| Convolution 3x3     	| 24 filters, 2x2 stride, 5x5 kernel, same padding|
| RELU					|												|
| Convolution 3x3     	| 36 filters, 2x2 stride, 5x5 kernel, same padding|
| RELU					|												|
| Convolution 3x3     	| 48 filters, 2x2 stride, 5x5 kernel, same padding|
| RELU					|												|
| Convolution 3x3     	| 64 filters, 1x1 stride, 3x3 kernel, valid padding|
| RELU					|												|
| Convolution 3x3     	| 36 filters, 2x2 stride, 5x5 kernel, valid padding|
| RELU					|												|
| Flatten					|												|
| Fully Connected				|  500 outputs			|
| Dropout				|  0.1			|
| Fully Connected				|  150 outputs	|
| Fully Connected				|  10 outputs	|
| Fully Connected				|  1 output (the result)	|

***hyper-parameters used:***

* EPOCHS: 20
* batch size: 128
* learning rate: 0.0001

Please note that this model was chosen after much experimentation with different models and different hyper-parameters.

#### 2. Attempts to reduce overfitting in the model

Overfitting is was a big problem initially, however, it was tackled in the final model by employing the following strategies:

- A dropout layer was added with dropout probability of 0.1 (*line 135 in network.py*). This resulted in a more robust model as during each training iteration half the input nodes were set to 0, resulting in the remaining half to account for the error.

- The training data itself was generated by employing a lot of variation in driving style sharp turns, smooth turns, driving in a straight-line etc.

These two steps helped eliminate most of the overfitting in the data.


#### 3. Model parameter tuning

The model used an adam optimizer, so the learning rate was not tuned manually (*line 147 in network.py*).

Mean Square Error is used as the error measure. Specific hyperparameters used are listed in the previous section.

#### 4. Appropriate training data

Training data was generated by driving the car in the center of the road and through a combination of making some slight and sharp right and left turns. The car was never allowed to leave the road during the training.

For details about how I created the training data, see the next section.

### Training Strategy

#### 1. Solution Design Approach

In order to solve this problem, we first employed a smaller less complex Convolutional Neural Network and training approach. The car was only run for one lap on the track in a straight-forward manner (few turns). There were only two convolutional layers and no dropout. Unsurprisingly, this network was not generating good results. At the car would veer off the track and not know how to drive back onto it.

Hence, a more complicated deeper model was used. Intuitively, since the images are large (160x32) and there are a lot of features in the images that need to extracted, it made sense that a deeper network would perform better. However, a deeper network with the same training data didnt really perform any better. This meant that there was a need for new data.

At first, this was accomplished by also adding the side images (and their corresponding angles) to the center images. The side angles were converted to center angles by adding or subtracting a correction factor of 0.2. This resulted in 3 times the data and made the training process much slower. Although this improved the quality of the car driving in autonomous mode, the car was able to travel farther, the improvement was only slight. Hence, we abandoned this approach and decided that it was time to collect new data.

The car made to run for 2 laps as opposed to just 1 lap. This generated more data and the same time provided an opportunity to vary the driving style. We incorporated sudden sharp turns, slight turns, straight driving etc. into this approach. This data added with a deeper network resulted in the final model. The layers of the final CNN are described in a previous section.

The performance of the model was decided based on the mean squared error, which is in the case based on the difference between the predicted steering angle and the actual steering angle for a given image.

Overfitting was tackled in the final model by using a dropout layer with a dropout probability of 0.1. In addition, the varied driving style in the training data also helped reduce overfitting.

The final model resulted in a car that was able to drive autonomously without leaving the track.

#### 2. Creation of the Training Set & Preprocessing

The entire driving process resulted in about 9000 images. As described above since the car was driven in a varied manner, we had different types of driving images. An example of center driving:

![center][image1]

Here are some examples of driving with sharp left or right turns:

![left turn][image2]
![right turn][image3]

After the training data was obtained, we processed the images (*lines 47 to 80 in network.py*). In this step, we also randomly shuffled the data and split it into training and validation sets. The validation data is not used directly in backpropagation, but is used as a measure of how well the model is performing and whether or not the error is truly decreasing. A decrease in training error but an increase in the validation error indicated overfitting.  

We preprocessed the images by first normalizing them and then cropping them (*lines 93 to 96 in network.py*). No other preprocessing was performed, the images were inputted as color and not grayscale.

### Main Takeaways

This project demonstrated the power of neural networks and deep learning. Without using any computer vision techniques and with out extracting any features from the images, enable a car to drive autonomously. Further more, this project demonstrates the importance of good data. As we have seen, a deep neural network is only useful if the data used to train it is well prepared. Finally, overfitting can cause problems and a dropout layer is a useful and easy way to tackle it.
